from fastapi import FastAPI, UploadFile, File, Form, Depends
from fastapi.responses import RedirectResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from pydantic import BaseModel
from langserve import add_routes
from chat import chain as chat_chain
from chat import llm
from dotenv import load_dotenv
from typing import Optional
from PIL import Image
import json
import pytesseract
import io
import os
from langchain_chroma import Chroma  # ìµœì‹  íŒ¨í‚¤ì§€ë¡œ ì„í¬íŠ¸
from langchain_ollama import OllamaEmbeddings
from langchain.schema import Document
import uuid 
import logging
import datetime
import xml.etree.ElementTree as ET
import pandas as pd
import requests
from apscheduler.schedulers.background import BackgroundScheduler
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain.chains.retrieval_qa.base import RetrievalQA
from data import fetch_data_prec,fetch_data_law,fetch_data_ordin
from rag import save_files_to_vector_db,save_to_vector_db,get_vector_db


# í™˜ê²½ ì„¤ì • íŒŒì¼ ë¡œë”©
load_dotenv()

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì²´ ì´ˆê¸°í™”
app = FastAPI()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

logger.info("ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")

# í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
timestamp = datetime.datetime.now().isoformat()  # ISO í˜•ì‹ìœ¼ë¡œ ë‚ ì§œ ë° ì‹œê°„ ë°˜í™˜

# Tesseract OCR ê²½ë¡œ ì„¤ì •
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# Chroma ë²¡í„° DB ì„¤ì •
CHROMA_DB_DIR = "vectorstore"
PDF_DIR = "pdfs"
embeddings = OllamaEmbeddings(model="llama3.1-instruct-8b:latest")

# ê¸°ì¡´ DB ë””ë ‰í† ë¦¬ ì‚­ì œ
#if os.path.exists(CHROMA_DB_DIR):
#    import shutil
#    shutil.rmtree(CHROMA_DB_DIR)  # ë””ë ‰í† ë¦¬ ë° ê·¸ ì•ˆì˜ ë‚´ìš© ëª¨ë‘ ì‚­ì œ
    
os.makedirs(CHROMA_DB_DIR, exist_ok=True)

##################################### 30ë¶„ ë§ˆë‹¤ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„± 
scheduler = BackgroundScheduler()

def fetch_all_data():
    fetch_data_prec()
    fetch_data_law()
    fetch_data_ordin()
    
     # fetch_all_dataê°€ ì™„ë£Œëœ í›„ì— save_files_to_vector_db í˜¸ì¶œ
    save_files_to_vector_db()

# êµ­ê°€ë²•ë ¹ì •ë³´ ì—‘ì…€ ì—…ë°ì´íŠ¸
scheduler.add_job(fetch_all_data, trigger='interval', hours=24)


# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # ë°°í¬ì‹œ ë„ë©”ì¸
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)

# ê¸°ë³¸ ê²½ë¡œ("/")ì— ëŒ€í•œ ë¦¬ë‹¤ì´ë ‰ì…˜ ì²˜ë¦¬
@app.get("/")
async def redirect_root_to_docs():
    return RedirectResponse("/prompt/playground")

@app.get("/prompt/playground")
async def playground():
    return {"message": "Welcome to the Playground!"}

########### ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ###########

# ì…ë ¥ ë°ì´í„° ëª¨ë¸
class InputChat(BaseModel):
    messages: list[str]

# ëŒ€í™”í˜• API ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat")
async def chat(input: str = Form(...), file: Optional[UploadFile] = File(None),  document_type: str = "message", vector_db: Chroma = Depends(get_vector_db)):
    # vector_dbëŠ” ì´ì œ Chroma ê°ì²´ë¡œ ìë™ ì£¼ì…ë¨
    try:
        input_data = InputChat(**json.loads(input))
        result = {}

        # ëŒ€í™” ID ìƒì„±
        conversation_id = str(uuid.uuid4())

        # ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œëœ ê²½ìš° OCR ì²˜ë¦¬
        if file:
            image = Image.open(io.BytesIO(await file.read()))
            ocr_text = pytesseract.image_to_string(image, lang="kor+eng")
            input_data.messages.append(ocr_text)
            result["ocr_text"] = ocr_text
            
        # # ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        # query = input_data.messages[-1]  # ìµœì‹  ë©”ì‹œì§€ ì‚¬ìš©
        # docs = retriever.invoke(query)

        # # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ LLM ì…ë ¥ì— ì¶”ê°€
        # context = "\n\n".join([doc.page_content for doc in docs]) if docs else "ê´€ë ¨ ì •ë³´ ì—†ìŒ"
        # input_data.messages.append(f"ğŸ” ì°¸ê³  ì •ë³´:\n{context}")

        # # ì±—ë´‡ ì‘ë‹µ ìƒì„±
        # result["chatbot_response"] = chat_chain.invoke(input_data.messages)    
        
        # ì±—ë´‡ ì‘ë‹µë§Œ ìƒì„± í”„ë¡¬í”„íŒ… Test
        result["chatbot_response"] = chat_chain.invoke(input_data.messages)

        # ë²¡í„° DBì— ë©”ì‹œì§€ ì €ì¥
        save_to_vector_db(input_data.messages, document_type, conversation_id, vector_db)

        return JSONResponse(content={"message": "Chat response", "type": document_type, "result": result, "input_messages": input_data.messages})

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)


# ëŒ€í™”í˜• ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
add_routes(
    app,
    chat_chain.with_types(input_type=InputChat),
    path="/chat",
    enable_feedback_endpoint=True,
    enable_public_trace_link_endpoint=True,
    playground_type="chat",
)

# ì„œë²„ ì‹¤í–‰ ì„¤ì •
if __name__ == "__main__":
    scheduler.start()

    # ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ ì‹¤í–‰
    # fetch_all_data()

    # FastAPI ì„œë²„ ì‹¤í–‰
    uvicorn.run(app, host="0.0.0.0", port=8000)
